{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, a binary logistic regression describes the relationship between the dependent binary variable and one or more independent variable/s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X represents the size of a tumor in centimeters.\n",
    "X = numpy.array([3.78, 2.44, 2.09, 0.14, 1.72, 1.65, 4.92, 4.37, 4.96, 4.52, 3.69, 5.88]).reshape(-1,1)\n",
    "\n",
    "#Note: X has to be reshaped into a column from a row for the LogisticRegression() function to work.\n",
    "#y represents whether or not the tumor is cancerous (0 for \"No\", 1 for \"Yes\").\n",
    "y = numpy.array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr = linear_model.LogisticRegression()\n",
    "logr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict if tumor is cancerous where the size is 3.46mm:\n",
    "predicted = logr.predict(numpy.array([3.46]).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Data Shape (1797, 64)\n",
      "Label Data Shape (1797,)\n"
     ]
    }
   ],
   "source": [
    "# Print to show there are 1797 images (8 by 8 images for a dimensionality of 64)\n",
    "print(\"Image Data Shape\" , digits.data.shape)\n",
    "# Print to show there are 1797 labels (integers from 0–9)\n",
    "print(\"Label Data Shape\", digits.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1=[1,3,5,6]\n",
    "L2=[100,200,300,400]\n",
    "L=zip(L1,L2)\n",
    "for i in L:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,4))\n",
    "for index, (image, label) in enumerate(zip(X[0:5], y[0:5])):\n",
    "    plt.subplot(1, 5, index + 1)\n",
    "    plt.imshow(np.reshape(image, (8,8)), cmap=plt.cm.gray)\n",
    "    plt.title('Training: %i\\n' % label, fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "digreg = LogisticRegression(multi_class='multinomial',solver='newton-cg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', solver='newton-cg')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = digreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 0, 7, 1, 0, 6, 1, 5, 4, 9, 2, 7, 8, 4, 6, 9, 3, 7, 4, 7, 1,\n",
       "       8, 6, 0, 9, 6, 1, 3, 7, 5, 9, 8, 3, 2, 8, 8, 1, 1, 0, 7, 9, 0, 0,\n",
       "       8, 7, 2, 7, 4, 3, 4, 3, 4, 0, 4, 7, 0, 5, 5, 5, 2, 1, 7, 0, 5, 1,\n",
       "       8, 3, 3, 4, 0, 3, 7, 4, 3, 4, 2, 9, 7, 3, 2, 5, 3, 4, 1, 5, 5, 2,\n",
       "       1, 2, 2, 2, 2, 7, 0, 8, 1, 7, 4, 2, 3, 8, 2, 3, 3, 0, 2, 9, 5, 2,\n",
       "       3, 2, 8, 1, 1, 9, 1, 2, 0, 4, 8, 5, 4, 4, 7, 6, 7, 6, 6, 1, 7, 5,\n",
       "       6, 3, 8, 3, 7, 1, 8, 5, 3, 4, 7, 8, 5, 0, 6, 0, 6, 3, 7, 6, 5, 6,\n",
       "       2, 2, 2, 3, 0, 7, 6, 5, 6, 4, 1, 0, 6, 0, 6, 4, 0, 9, 3, 5, 1, 2,\n",
       "       3, 1, 9, 0, 7, 6, 2, 9, 3, 5, 3, 4, 6, 3, 3, 7, 4, 9, 2, 7, 6, 1,\n",
       "       6, 8, 4, 0, 3, 1, 0, 9, 9, 9, 0, 1, 2, 6, 8, 0, 9, 5, 9, 8, 2, 3,\n",
       "       5, 3, 0, 8, 7, 4, 0, 3, 3, 3, 6, 3, 3, 2, 9, 1, 6, 9, 0, 4, 2, 2,\n",
       "       7, 9, 1, 6, 7, 6, 8, 5, 1, 8, 3, 4, 0, 6, 4, 8, 5, 3, 6, 3, 1, 4,\n",
       "       0, 4, 4, 8, 7, 9, 1, 5, 2, 7, 0, 9, 0, 4, 4, 0, 1, 0, 6, 4, 2, 8,\n",
       "       5, 0, 2, 6, 0, 1, 8, 2, 0, 9, 5, 6, 2, 0, 5, 0, 9, 1, 4, 7, 1, 7,\n",
       "       0, 6, 6, 8, 0, 2, 2, 6, 9, 9, 7, 5, 1, 4, 6, 4, 6, 1, 9, 4, 7, 1,\n",
       "       3, 7, 8, 1, 6, 9, 8, 3, 2, 4, 8, 7, 5, 5, 6, 9, 9, 8, 3, 0, 0, 4,\n",
       "       9, 3, 0, 4, 9, 4, 2, 5, 4, 9, 6, 4, 2, 6, 0, 0, 5, 6, 7, 1, 9, 2,\n",
       "       5, 1, 5, 9, 8, 7, 7, 0, 6, 9, 3, 1, 3, 3, 9, 8, 7, 0, 2, 3, 9, 9,\n",
       "       2, 8, 1, 9, 2, 3, 0, 0, 7, 3, 8, 7, 9, 9, 7, 1, 0, 4, 5, 4, 1, 7,\n",
       "       3, 6, 5, 4, 9, 0, 5, 9, 1, 4, 5, 0, 4, 3, 4, 2, 7, 9, 0, 8, 7, 8,\n",
       "       6, 9, 4, 5, 7, 8, 3, 7, 8, 3, 2, 6, 6, 7, 1, 0, 8, 4, 8, 9, 5, 4,\n",
       "       1, 2, 5, 3, 3, 3, 2, 1, 8, 7, 6, 2, 3, 6, 2, 5, 2, 6, 4, 5, 4, 4,\n",
       "       9, 7, 9, 1, 0, 2, 6, 9, 3, 6, 7, 3, 6, 4, 7, 8, 4, 1, 2, 1, 1, 0,\n",
       "       7, 3, 0, 3, 2, 9, 4, 5, 9, 9, 4, 8, 3, 3, 3, 8, 4, 1, 4, 5, 8, 3,\n",
       "       9, 5, 4, 7, 7, 4, 0, 1, 7, 1, 8, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression model is: 96.85185185185186\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Logistic Regression model is:\",\n",
    "metrics.accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict labels for new data (new images)\n",
    "# Returns a NumPy Array\n",
    "# Predict for One Observation (image)\n",
    "digreg.predict(X_test[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.linear_model.LogisticRegression\n",
    "lass sklearn.linear_model.LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "penalty: {'l1’, 'l2’, ‘elasticnet’, ‘none’}, default=’l2’\n",
    "\n",
    "Used to specify the norm used in the penalization. The ‘newton-cg’, ‘sag’ and ‘lbfgs’ solvers support only l2 penalties. ‘elasticnet’ is only supported by the ‘saga’ solver. If ‘none’ (not supported by the liblinear solver), no regularization is applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "solver: {‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’\n",
    "\n",
    "Algorithm to use in the optimization problem.\n",
    "\n",
    "1. For small datasets, ‘liblinear’ is a good choice, whereas ‘sag’ and ‘saga’ are faster for large ones.\n",
    "\n",
    "2. For multiclass problems, only ‘newton-cg’, ‘sag’, ‘saga’ and ‘lbfgs’ handle multinomial loss; ‘liblinear’ is limited to one-versus-rest schemes.\n",
    "\n",
    "3. ‘newton-cg’, ‘lbfgs’, ‘sag’ and ‘saga’ handle L2 or no penalty\n",
    "\n",
    "4. ‘liblinear’ and ‘saga’ also handle L1 penalty\n",
    "\n",
    "5. ‘saga’ also supports ‘elasticnet’ penalty\n",
    "\n",
    "6. ‘liblinear’ does not support setting penalty='none'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_iter : int, default: 100\n",
    "\n",
    "Useful only for the newton-cg, sag and lbfgs solvers. Maximum number of iterations taken for the solvers to converge.\n",
    "\n",
    "multi_class : str, {‘ovr’, ‘multinomial’}, default: ‘ovr’\n",
    "\n",
    "Multiclass option can be either ‘ovr’ or ‘multinomial’. If the option chosen is ‘ovr’, then a binary problem is fit for each label. Else the loss minimised is the multinomial loss fit across the entire probability distribution. Does not work for liblinear solver.\n",
    "\n",
    "New in version 0.18: Stochastic Average Gradient descent solver for ‘multinomial’ case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "wine_names = ['Class', 'Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash', 'Magnesium', 'Total phenols', \\\n",
    "              'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue', 'OD280/OD315',\\\n",
    "              'Proline']\n",
    "wine_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data', names = wine_names) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>3</td>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>3</td>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>3</td>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>3</td>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>3</td>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "0        1    14.23        1.71  2.43               15.6        127   \n",
       "1        1    13.20        1.78  2.14               11.2        100   \n",
       "2        1    13.16        2.36  2.67               18.6        101   \n",
       "3        1    14.37        1.95  2.50               16.8        113   \n",
       "4        1    13.24        2.59  2.87               21.0        118   \n",
       "..     ...      ...         ...   ...                ...        ...   \n",
       "173      3    13.71        5.65  2.45               20.5         95   \n",
       "174      3    13.40        3.91  2.48               23.0        102   \n",
       "175      3    13.27        4.28  2.26               20.0        120   \n",
       "176      3    13.17        2.59  2.37               20.0        120   \n",
       "177      3    14.13        4.10  2.74               24.5         96   \n",
       "\n",
       "     Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0             2.80        3.06                  0.28             2.29   \n",
       "1             2.65        2.76                  0.26             1.28   \n",
       "2             2.80        3.24                  0.30             2.81   \n",
       "3             3.85        3.49                  0.24             2.18   \n",
       "4             2.80        2.69                  0.39             1.82   \n",
       "..             ...         ...                   ...              ...   \n",
       "173           1.68        0.61                  0.52             1.06   \n",
       "174           1.80        0.75                  0.43             1.41   \n",
       "175           1.59        0.69                  0.43             1.35   \n",
       "176           1.65        0.68                  0.53             1.46   \n",
       "177           2.05        0.76                  0.56             1.35   \n",
       "\n",
       "     Color intensity   Hue  OD280/OD315  Proline  \n",
       "0               5.64  1.04         3.92     1065  \n",
       "1               4.38  1.05         3.40     1050  \n",
       "2               5.68  1.03         3.17     1185  \n",
       "3               7.80  0.86         3.45     1480  \n",
       "4               4.32  1.04         2.93      735  \n",
       "..               ...   ...          ...      ...  \n",
       "173             7.70  0.64         1.74      740  \n",
       "174             7.30  0.70         1.56      750  \n",
       "175            10.20  0.59         1.56      835  \n",
       "176             9.30  0.60         1.62      840  \n",
       "177             9.20  0.61         1.60      560  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df = pd.DataFrame(wine_data)\n",
    "wine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Class', 'Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash',\n",
       "       'Magnesium', 'Total phenols', 'Flavanoids', 'Nonflavanoid phenols',\n",
       "       'Proanthocyanins', 'Color intensity', 'Hue', 'OD280/OD315', 'Proline'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df.Class = wine_df.Class - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "173    2\n",
       "174    2\n",
       "175    2\n",
       "176    2\n",
       "177    2\n",
       "Name: Class, Length: 178, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df.Class.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  Total phenols  \\\n",
      "0      14.23        1.71  2.43               15.6        127           2.80   \n",
      "1      13.20        1.78  2.14               11.2        100           2.65   \n",
      "2      13.16        2.36  2.67               18.6        101           2.80   \n",
      "3      14.37        1.95  2.50               16.8        113           3.85   \n",
      "4      13.24        2.59  2.87               21.0        118           2.80   \n",
      "..       ...         ...   ...                ...        ...            ...   \n",
      "173    13.71        5.65  2.45               20.5         95           1.68   \n",
      "174    13.40        3.91  2.48               23.0        102           1.80   \n",
      "175    13.27        4.28  2.26               20.0        120           1.59   \n",
      "176    13.17        2.59  2.37               20.0        120           1.65   \n",
      "177    14.13        4.10  2.74               24.5         96           2.05   \n",
      "\n",
      "     Flavanoids  Nonflavanoid phenols  Proanthocyanins  Color intensity   Hue  \\\n",
      "0          3.06                  0.28             2.29             5.64  1.04   \n",
      "1          2.76                  0.26             1.28             4.38  1.05   \n",
      "2          3.24                  0.30             2.81             5.68  1.03   \n",
      "3          3.49                  0.24             2.18             7.80  0.86   \n",
      "4          2.69                  0.39             1.82             4.32  1.04   \n",
      "..          ...                   ...              ...              ...   ...   \n",
      "173        0.61                  0.52             1.06             7.70  0.64   \n",
      "174        0.75                  0.43             1.41             7.30  0.70   \n",
      "175        0.69                  0.43             1.35            10.20  0.59   \n",
      "176        0.68                  0.53             1.46             9.30  0.60   \n",
      "177        0.76                  0.56             1.35             9.20  0.61   \n",
      "\n",
      "     OD280/OD315  Proline  \n",
      "0           3.92     1065  \n",
      "1           3.40     1050  \n",
      "2           3.17     1185  \n",
      "3           3.45     1480  \n",
      "4           2.93      735  \n",
      "..           ...      ...  \n",
      "173         1.74      740  \n",
      "174         1.56      750  \n",
      "175         1.56      835  \n",
      "176         1.62      840  \n",
      "177         1.60      560  \n",
      "\n",
      "[178 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = wine_df.drop(labels='Class',axis=1)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "173    3\n",
      "174    3\n",
      "175    3\n",
      "176    3\n",
      "177    3\n",
      "Name: Class, Length: 178, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Y = wine_df['Class']\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "scaledX=sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.51861254, -0.5622498 ,  0.23205254, ...,  0.36217728,\n",
       "         1.84791957,  1.01300893],\n",
       "       [ 0.24628963, -0.49941338, -0.82799632, ...,  0.40605066,\n",
       "         1.1134493 ,  0.96524152],\n",
       "       [ 0.19687903,  0.02123125,  1.10933436, ...,  0.31830389,\n",
       "         0.78858745,  1.39514818],\n",
       "       ...,\n",
       "       [ 0.33275817,  1.74474449, -0.38935541, ..., -1.61212515,\n",
       "        -1.48544548,  0.28057537],\n",
       "       [ 0.20923168,  0.22769377,  0.01273209, ..., -1.56825176,\n",
       "        -1.40069891,  0.29649784],\n",
       "       [ 1.39508604,  1.58316512,  1.36520822, ..., -1.52437837,\n",
       "        -1.42894777, -0.59516041]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaledX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaledX, Y, test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', solver='newton-cg')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=LogisticRegression(multi_class='multinomial',solver='newton-cg')\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredict=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14,  0,  0],\n",
       "       [ 0, 16,  0],\n",
       "       [ 0,  0,  6]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,ypredict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,ypredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "sc=cross_val_score(model,X_train,y_train,cv=5)\n",
    "print(sc)\n",
    "print(sc.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the LogisticRegression class uses the L2 penalty with a weighting of coefficients set to 1.0. The type of penalty can be set via the “penalty” argument with values of “l1“, “l2“, “elasticnet” (e.g. both), although not all solvers support all penalty types. The weighting of the coefficients in the penalty can be set via the “C” argument.\n",
    "\n",
    "LogisticRegression(multi_class='multinomial', solver='lbfgs', penalty='l2', C=1.0)\n",
    "\n",
    "C : float, default=1.0\n",
    "Inverse of regularization strength; must be a positive float.\n",
    "\n",
    "This means that values close to 1.0 indicate very little penalty and values close to zero indicate a strong penalty. A C value of 1.0 may indicate no penalty at all.\n",
    "\n",
    "C close to 1.0: Light penalty.\n",
    "C close to 0.0: Strong penalty.\n",
    "\n",
    "lets explore the L2 penalty with weighting values in the range from 0.0001 to 1.0 on a log scale, in addition to no penalty or 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "x,y=make_classification(n_samples=1000,n_features=20,n_informative=15,n_classes=3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv(\"d://MLDataSet/iris_dataset.csv\")\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iris.drop('flower', axis=1)\n",
    "y = iris['flower']\n",
    "trainX, testX, trainY, testY = train_test_split(x, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(solver='newton-cg', multi_class='multinomial')\n",
    "log_reg.fit(trainX, trainY)\n",
    "y_pred = log_reg.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: {:.2f}'.format(accuracy_score(testY, y_pred)))\n",
    "print('Error rate: {:.2f}'.format(1 - accuracy_score(testY, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores from cross validation:\n",
    "clf = LogisticRegression(solver='newton-cg', multi_class='multinomial')\n",
    "scores = cross_val_score(clf, trainX, trainY, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as py\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Load data\n",
    "x=np.random.randint(50,size=50)\n",
    "x=x.reshape(-1,1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#x=np.arange(10).reshape(-1,1)\n",
    "#y=np.array([0,1,1,1,0,0,1,1,0,1])\n",
    "y=np.random.randint(2, size=50)\n",
    "\n",
    "#The array x is required to be two-dimensional. \n",
    "#It should have one column for each input, and the number of rows should be equal\n",
    "#to the number of observations. To make x two-dimensional, you apply .reshape() \n",
    "#with the arguments -1 to get as many rows as needed and 1 to get one column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The reshape() function is used to give a new shape to an array without changing its data.\n",
    "# x = np.array([[2,3,4], [5,6,7]])      \n",
    "# np.reshape(x, (3, 2))\n",
    "\n",
    "#>>> x = np.array([[2,3,4], [5,6,7]]) \n",
    "#>>> np.reshape(x, (3, -1))\n",
    "a=np.arange(20)\n",
    "print(a)\n",
    "b=np.reshape(a,(5,4))\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Model\n",
    "lr=LogisticRegression()\n",
    "\n",
    "#Syntax\n",
    "\n",
    "#class sklearn.linear_model.LogisticRegression(penalty='l2', *, dual=False, \n",
    "#tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, \n",
    "#class_weight=None, random_state=None, solver='lbfgs', max_iter=100, \n",
    "#multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "\n",
    "#LIBLINEAR is a linear classifier for data \n",
    "\n",
    "#solver{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’\n",
    "\n",
    "#Algorithm to use in the optimization problem.\n",
    "\n",
    "#For small datasets, ‘liblinear’ is a good choice, whereas ‘sag’ and ‘saga’ are faster for large ones.\n",
    "\n",
    "#For multiclass problems, only ‘newton-cg’, ‘sag’, ‘saga’ and ‘lbfgs’ \n",
    "\n",
    "#handle multinomial loss; ‘liblinear’ is limited to one-versus-rest schemes.\n",
    "\n",
    "#‘newton-cg’, ‘lbfgs’, ‘sag’ and ‘saga’ handle L2 or no penalty\n",
    "\n",
    "#‘liblinear’ and ‘saga’ also handle L1 penalty\n",
    "\n",
    "#penalty is a string ('l2' by default) that decides whether there is regularization \n",
    "#and which approach to use. Other options are 'l1', 'elasticnet', and 'none'.\n",
    "\n",
    "#tol is a floating-point number (0.0001 by default) that defines the tolerance for stopping the procedure.\n",
    "\n",
    "#C is a positive floating-point number (1.0 by default) that defines the relative strength of regularization. Smaller values indicate stronger regularization.\n",
    "\n",
    "#fit_intercept is a Boolean (True by default) that decides whether to calculate the intercept 𝑏₀ (when True) or consider it equal to zero (when False).\n",
    "\n",
    "#intercept_scaling is a floating-point number (1.0 by default) that defines the scaling of the intercept 𝑏₀.\n",
    "\n",
    "#class_weight is a dictionary, 'balanced', or None (default) that defines the weights related to each class. When None, all classes have the weight one.\n",
    "\n",
    "#random_state is an integer, an instance of numpy.RandomState, or None (default) that defines what pseudo-random number generator to use.\n",
    "\n",
    "#solver is a string ('liblinear' by default) that decides what solver to use for fitting the model. Other options are 'newton-cg', 'lbfgs', 'sag', and 'saga'.\n",
    "\n",
    "#multi_class is a string ('ovr' by default) that decides the approach to use for handling multiple classes. Other options are 'multinomial' and 'auto'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Fitting\n",
    "\n",
    "lr.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr.intercept_)\n",
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "x_new=[]\n",
    "for i in range(50):\n",
    "    x_new.append(random.randint(1,100))\n",
    "x_new=np.array(x_new).reshape(-1,1)\n",
    "print(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict\n",
    "print(\"result after prediction..........\")\n",
    "prediction_result = lr.predict(x_new)\n",
    "print(prediction_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Evaluate the Model\n",
    "Once a model is defined, you can check its performance with .predict_proba(), \n",
    "which returns the matrix of probabilities that the predicted output is equal to zero or one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict_proba(x_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the matrix above, each row corresponds to a single observation. The first column is the probability of the predicted output being zero, that is 1 - 𝑝(𝑥). The second column is the probability that the output is one, or 𝑝(𝑥)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score() takes the input and output as arguments and returns the ratio of the number of correct predictions to the number of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y, lr.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19 true negative predictions: The first 19 observations are zeros predicted correctly.\n",
    "\n",
    "13 false negative predictions: These are 13 wrongly predicted as zeros.\n",
    "\n",
    "7 false positive prediction: 7 observation is a zero that was wrongly predicted as one.\n",
    "\n",
    "11 true positive predictions: The last 11 observations are ones predicted correctly.\n",
    "\n",
    "It’s often useful to visualize the confusion matrix. You can do that with .imshow() from Matplotlib, which accepts the confusion matrix as the argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y, lr.predict(x))\n",
    "\n",
    "fig, ax = py.subplots(figsize=(4, 4))\n",
    "ax.imshow(cm)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "py.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get a more comprehensive report on the classification with classification_report():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y, lr.predict(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py.plot(y, lr.predict(x))\n",
    "py.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# improving the model\n",
    "You can improve your model by setting different parameters. For example, let’s work with the regularization strength C equal to 10.0, instead of the default value of 1.0\n",
    "\n",
    "Regularization does NOT improve the performance on the data set that the algorithm used to learn the model parameters (feature weights). However, it can improve the generalization performance, i.e., the performance on new, unseen data, which is exactly what we want.\n",
    "\n",
    "In intuitive terms, we can think of regularization as a penalty against complexity. Increasing the regularization strength penalizes \"large\" weight coefficients -- our goal is to prevent that our model picks up \"peculiarities,\" \"noise,\" or \"imagines a pattern where there is none.\"\n",
    "\n",
    "Again, we don't want the model to memorize the training dataset, we want a model that generalizes well to new, unseen data.\n",
    "\n",
    "L2 & L1 regularization\n",
    "\n",
    "L1 and L2 are the most common types of regularization. These update the general cost function by adding another term known as the regularization term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', C=10.0, random_state=0)\n",
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.intercept_)\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the absolute values of the intercept 𝑏₀ and the coefficient 𝑏₁ are larger. This is the case because the larger value of C means weaker regularization, or weaker penalization related to high values of 𝑏₀ and 𝑏₁.\n",
    "\n",
    "Different values of 𝑏₀ and 𝑏₁ imply a change of the logit 𝑓(𝑥), different values of the probabilities 𝑝(𝑥), a different shape of the regression line, and possibly changes in other predicted outputs and classification performance. \n",
    "\n",
    "The boundary value of 𝑥 for which 𝑝(𝑥)=0.5 and 𝑓(𝑥)=0 is higher now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y, model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y, model.predict(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression-Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Load data\n",
    "\n",
    "data = pd.read_csv('f:\\\\MLDataSet\\logisticReg.csv', delimiter=',')\n",
    "data.sample(5)\n",
    "#print(data)\n",
    "#Xset1=data['Gender'].values\n",
    "#Xset2=data['Height'].values\n",
    "#X=[Xset1,Xset2]\n",
    "#print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gender = pd.get_dummies(data['Gender'], drop_first=True)\n",
    "print(Gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data, Gender], axis=1)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Gender'], axis=1, inplace=True)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data[['Height','Weight']]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=data['Male']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.LogisticRegression()\n",
    "fitted_model = clf.fit(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model\n",
    "Ypred=clf.predict(X)\n",
    "print(Ypred)\n",
    "print(\"Class Probabilities--\")\n",
    "prob=clf.predict_proba(X)\n",
    "print(prob)\n",
    "\n",
    "print(\"Model Score---\")\n",
    "sc=clf.score(X,Y)\n",
    "print(sc)\n",
    "print(\"Confusion Matrix---\")\n",
    "conf=confusion_matrix(Y,Ypred)\n",
    "print(conf)\n",
    "report=classification_report(Y,Ypred)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict\n",
    "print(\"result after prediction..........\")\n",
    "prediction_result = clf.predict([(50.8,345)])\n",
    "print(prediction_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h=float(input(\"provide Height\"))\n",
    "w=float(input(\"provide weight\"))\n",
    "user_pred=clf.predict([(h,w)])\n",
    "print(user_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Project with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "data = pd.read_csv(\"d:\\\\MLDataSet\\\\titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Owen Harris Braund</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. John Bradley (Florence Briggs Thayer) Cum...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss. Laina Heikkinen</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. Jacques Heath (Lily May Peel) Futrelle</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. William Henry Allen</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  \\\n",
       "0         0       3                             Mr. Owen Harris Braund   \n",
       "1         1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   \n",
       "2         1       3                              Miss. Laina Heikkinen   \n",
       "3         1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   \n",
       "4         0       3                            Mr. William Henry Allen   \n",
       "\n",
       "      Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
       "0    male  22.0                        1                        0   7.2500  \n",
       "1  female  38.0                        1                        0  71.2833  \n",
       "2  female  26.0                        0                        0   7.9250  \n",
       "3  female  35.0                        1                        0  53.1000  \n",
       "4    male  35.0                        0                        0   8.0500  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Survived  Pclass   Name    Sex    Age  Siblings/Spouses Aboard  \\\n",
      "0       False   False  False  False  False                    False   \n",
      "1       False   False  False  False  False                    False   \n",
      "2       False   False  False  False  False                    False   \n",
      "3       False   False  False  False  False                    False   \n",
      "4       False   False  False  False  False                    False   \n",
      "..        ...     ...    ...    ...    ...                      ...   \n",
      "882     False   False  False  False  False                    False   \n",
      "883     False   False  False  False  False                    False   \n",
      "884     False   False  False  False  False                    False   \n",
      "885     False   False  False  False  False                    False   \n",
      "886     False   False  False  False  False                    False   \n",
      "\n",
      "     Parents/Children Aboard   Fare  \n",
      "0                      False  False  \n",
      "1                      False  False  \n",
      "2                      False  False  \n",
      "3                      False  False  \n",
      "4                      False  False  \n",
      "..                       ...    ...  \n",
      "882                    False  False  \n",
      "883                    False  False  \n",
      "884                    False  False  \n",
      "885                    False  False  \n",
      "886                    False  False  \n",
      "\n",
      "[887 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "missing_values = data.isnull()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#A countplot is kind of likea histogram or a bar graph for some categorical area.\n",
    "#It simply shows the number of occurrences of an item based on a certain type of category.\n",
    "\n",
    "# Use the countplot() method to identify ratio of who survived vs. not with interest in Passenger class\n",
    "# x -> argument referes to column of interest\n",
    "# data -> argument refers to dataset\n",
    "# hue -> allows another level to subdivide data\n",
    "# palette -> argument refers to plot color\n",
    "sns.countplot(x='Survived', data=data, hue='Pclass')\n",
    "\n",
    "#sns.countplot(x='Survived', data=train)\n",
    "plt.figure(figsize=(10,7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Pclass', ylabel='Age'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x='Pclass',y='Age',data=data)\n",
    "\n",
    "#Boxplots are a measure of how well distributed the data in a data set is. \n",
    "#It divides the data set into three quartiles. \n",
    "#This graph represents the minimum, maximum, median, first quartile and \n",
    "#third quartile in the data set. \n",
    "#It is also useful in comparing the distribution of data across data sets \n",
    "#by drawing boxplots for each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     male\n",
      "0       1\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       1\n",
      "..    ...\n",
      "882     1\n",
      "883     0\n",
      "884     0\n",
      "885     1\n",
      "886     1\n",
      "\n",
      "[887 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "sex = pd.get_dummies(data['Sex'], drop_first=True)\n",
    "print(sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data, sex], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Sex','Name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into 'X' features and 'y' target label sets\n",
    "X = data[['Pclass', 'Age', 'Siblings/Spouses Aboard', 'Parents/Children Aboard', 'Fare', 'male']]\n",
    "Y = data['Survived']\n",
    "#print(X)\n",
    "#print(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split data set into training and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=101)\n",
    "#print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import module for fitting\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Create instance (i.e. object) of LogisticRegression\n",
    "logmodel = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model using the training data\n",
    "# X_train -> parameter supplies the data features\n",
    "# y_train -> parameter supplies the target labels\n",
    "model=logmodel.fit(X_train, Y_train)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test new pattern\n",
    "prediction_result = model.predict([(2,25.0,0,1,26,0)])\n",
    "print(prediction_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = model.predict(X_test)\n",
    "print(ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Model by reviewing the classification report or confusion matrix.\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test,ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
